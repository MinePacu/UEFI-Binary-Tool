#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ASUS ë°”ì´ë„ˆë¦¬ íŒŒì¼ ë¶„ì„ê¸°
ASUS BIOS/UEFI íŒŒì¼ì˜ êµ¬ì¡° ë¶„ì„ ë° ë§¤ì§ ë°”ì´íŠ¸ ê°ì§€
"""

import os
import re
import binascii
import struct
from collections import defaultdict
from datetime import datetime


class AsusFileAnalyzer:
    def __init__(self, file_path):
        self.file_path = file_path
        self.file_size = os.path.getsize(file_path)
        self.data = None
        
    def load_file(self):
        """íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ"""
        with open(self.file_path, 'rb') as f:
            self.data = f.read()
        print(f"íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {self.file_path}")
        print(f"íŒŒì¼ í¬ê¸°: {self.file_size:,} bytes ({self.file_size / 1024 / 1024:.2f} MB)")
        
    def analyze_magic_bytes(self):
        """ë§¤ì§ ë°”ì´íŠ¸ íŒ¨í„´ ë¶„ì„"""
        print("\n=== ë§¤ì§ ë°”ì´íŠ¸ ë¶„ì„ ===")
        
        # ì•Œë ¤ì§„ ë§¤ì§ ë°”ì´íŠ¸ íŒ¨í„´ë“¤
        magic_patterns = {
            b'MZ': 'PE/DOS Executable',
            b'PE\x00\x00': 'PE Header',
            b'\x7fELF': 'ELF Binary',
            b'PK\x03\x04': 'ZIP Archive',
            b'\x1f\x8b': 'GZIP',
            b'BM': 'Bitmap Image',
            b'\xff\xd8\xff': 'JPEG Image',
            b'\x89PNG': 'PNG Image',
            b'GIF8': 'GIF Image',
            b'RIFF': 'RIFF Container',
            b'\x00\x00\x01\x00': 'ICO File',
            b'_FVH': 'UEFI Firmware Volume',
            b'\x16\x00\x00\x00': 'Possible UEFI Volume',
            b'$FV$': 'UEFI Firmware Volume Signature',
            b'\x78\x56\x34\x12': 'Little Endian Magic',
            b'\x12\x34\x56\x78': 'Big Endian Magic',
        }
        
        # íŒŒì¼ ì‹œì‘ ë¶€ë¶„ì˜ ë§¤ì§ ë°”ì´íŠ¸ í™•ì¸
        found_magic = []
        for length in [2, 3, 4, 8, 16]:
            if len(self.data) >= length:
                header = self.data[:length]
                for magic, description in magic_patterns.items():
                    if header.startswith(magic):
                        print(f"ë§¤ì§ ë°”ì´íŠ¸ ë°œê²¬: {binascii.hexlify(magic).decode()} - {description}")
                        found_magic.append((magic, description))
        
        # ë§¤ì§ ë°”ì´íŠ¸ íŒ¨í„´ ë¹ˆë„ ë¶„ì„
        print(f"\n=== ë§¤ì§ íŒ¨í„´ ë¹ˆë„ ë¶„ì„ ===")
        magic_frequency = []
        
        for magic_bytes, description in magic_patterns.items():
            count = self.data.count(magic_bytes)
            if count > 0:
                frequency_per_mb = round(count / (self.file_size / 1024 / 1024), 2) if self.file_size > 0 else 0
                print(f"{binascii.hexlify(magic_bytes).decode()} ({description}): {count}ê°œ ({frequency_per_mb}/MB)")
                magic_frequency.append((description, count, frequency_per_mb))
        
        if magic_frequency:
            print(f"\në§¤ì§ íŒ¨í„´ ë¹ˆë„ ìš”ì•½:")
            magic_frequency.sort(key=lambda x: x[1], reverse=True)  # ê°œìˆ˜ë¡œ ì •ë ¬
            print(f"{'íŒ¨í„´':<25} {'ê°œìˆ˜':>6} {'ë¹ˆë„(/MB)':>10}")
            print("-" * 45)
            for desc, count, freq in magic_frequency[:5]:  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
                print(f"{desc:<25} {count:>6} {freq:>10}")
        
        # í—¥ìŠ¤ ë¤í”„ (ì²˜ìŒ 64ë°”ì´íŠ¸)
        print(f"\níŒŒì¼ ì‹œì‘ 64ë°”ì´íŠ¸ í—¥ìŠ¤ ë¤í”„:")
        hex_data = binascii.hexlify(self.data[:64]).decode()
        for i in range(0, len(hex_data), 32):
            offset = i // 2
            hex_line = hex_data[i:i+32]
            formatted_hex = ' '.join(hex_line[j:j+2] for j in range(0, len(hex_line), 2))
            ascii_data = ''.join(chr(b) if 32 <= b <= 126 else '.' for b in self.data[offset:offset+16])
            print(f"{offset:08x}: {formatted_hex:<47} |{ascii_data}|")
    
    def find_patterns(self):
        """íŒŒì¼ ë‚´ì—ì„œ ë°˜ë³µë˜ëŠ” íŒ¨í„´ ì°¾ê¸°"""
        print("\n=== íŒ¨í„´ ë¶„ì„ ===")
        
        # íŠ¹ì • íŒ¨í„´ë“¤ ê²€ìƒ‰
        patterns = {
            b'\x00' * 16: '16ë°”ì´íŠ¸ NULL íŒ¨í„´',
            b'\xff' * 16: '16ë°”ì´íŠ¸ 0xFF íŒ¨í„´',
            b'UEFI': 'UEFI ë¬¸ìì—´',
            b'BIOS': 'BIOS ë¬¸ìì—´',
            b'Award': 'Award BIOS',
            b'AMI': 'AMI BIOS',
            b'Phoenix': 'Phoenix BIOS',
            b'ASUS': 'ASUS ê´€ë ¨',
            b'Intel': 'Intel ê´€ë ¨',
            b'AMD': 'AMD ê´€ë ¨',
            b'\x89PNG': 'PNG ì´ë¯¸ì§€',
            b'\xff\xd8\xff': 'JPEG ì´ë¯¸ì§€',
            b'BM': 'BMP ì´ë¯¸ì§€',
            b'GIF8': 'GIF ì´ë¯¸ì§€',
            b'RIFF': 'RIFF íŒŒì¼',
            b'IEND': 'PNG ì¢…ë£Œ ë§ˆì»¤',
        }
        
        # íŒ¨í„´ ë¹ˆë„ í†µê³„
        pattern_stats = []
        
        for pattern, description in patterns.items():
            count = self.data.count(pattern)
            if count > 0:
                positions = []
                start = 0
                for _ in range(min(count, 5)):  # ìµœëŒ€ 5ê°œ ìœ„ì¹˜ë§Œ í‘œì‹œ
                    pos = self.data.find(pattern, start)
                    if pos != -1:
                        positions.append(f"0x{pos:08x}")
                        start = pos + 1
                    else:
                        break
                
                density_per_kb = round(count / (self.file_size / 1024), 3) if self.file_size > 0 else 0
                percentage_of_file = round((count * len(pattern) / self.file_size) * 100, 4) if self.file_size > 0 else 0
                
                print(f"{description}: {count}ê°œ ë°œê²¬ (ë°€ë„: {density_per_kb}/KB, ë¹„ìœ¨: {percentage_of_file}%)")
                print(f"  ìœ„ì¹˜: {', '.join(positions)}")
                if count > 5:
                    print(f"  (ì´ {count}ê°œ, ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ)")
                
                pattern_stats.append((description, count, density_per_kb, percentage_of_file))
        
        # ë¹ˆë„ í†µê³„ ìš”ì•½
        if pattern_stats:
            print(f"\n=== íŒ¨í„´ ë¹ˆë„ ìš”ì•½ (ìƒìœ„ 5ê°œ) ===")
            pattern_stats.sort(key=lambda x: x[1], reverse=True)  # ê°œìˆ˜ë¡œ ì •ë ¬
            print(f"{'íŒ¨í„´':<20} {'ê°œìˆ˜':>8} {'ë°€ë„(/KB)':>10} {'ë¹„ìœ¨(%)':>8}")
            print("-" * 50)
            for desc, count, density, percentage in pattern_stats[:5]:
                print(f"{desc:<20} {count:>8} {density:>10} {percentage:>8}")
    
    def analyze_embedded_files(self):
        """ì„ë² ë””ë“œ íŒŒì¼ ë¶„ì„"""
        print("\n=== ì„ë² ë””ë“œ íŒŒì¼ ë¶„ì„ ===")
        
        embedded_files = []
        
        # PNG íŒŒì¼ ì°¾ê¸°
        png_start = 0
        while True:
            png_pos = self.data.find(b'\x89PNG\r\n\x1a\n', png_start)
            if png_pos == -1:
                break
            
            # PNG ë ì°¾ê¸° (IEND ì²­í¬)
            iend_pos = self.data.find(b'IEND\xaeB`\x82', png_pos)
            if iend_pos != -1:
                png_size = iend_pos + 8 - png_pos
                embedded_files.append({
                    'type': 'PNG Image',
                    'start': png_pos,
                    'size': png_size,
                    'end': png_pos + png_size
                })
            png_start = png_pos + 1
        
        # JPEG íŒŒì¼ ì°¾ê¸°
        jpeg_start = 0
        while True:
            jpeg_pos = self.data.find(b'\xff\xd8\xff', jpeg_start)
            if jpeg_pos == -1:
                break
            
            # JPEG ë ì°¾ê¸° (FFD9)
            search_pos = jpeg_pos + 3
            jpeg_end = -1
            while search_pos < len(self.data) - 1:
                if self.data[search_pos:search_pos+2] == b'\xff\xd9':
                    jpeg_end = search_pos + 2
                    break
                search_pos += 1
            
            if jpeg_end != -1:
                jpeg_size = jpeg_end - jpeg_pos
                embedded_files.append({
                    'type': 'JPEG Image',
                    'start': jpeg_pos,
                    'size': jpeg_size,
                    'end': jpeg_end
                })
            jpeg_start = jpeg_pos + 1
        
        # BMP íŒŒì¼ ì°¾ê¸°
        bmp_start = 0
        while True:
            bmp_pos = self.data.find(b'BM', bmp_start)
            if bmp_pos == -1:
                break
            
            # BMP í—¤ë”ì—ì„œ íŒŒì¼ í¬ê¸° ì½ê¸°
            if bmp_pos + 6 <= len(self.data):
                try:
                    bmp_size_bytes = self.data[bmp_pos + 2:bmp_pos + 6]
                    bmp_size = struct.unpack('<I', bmp_size_bytes)[0]
                    
                    # í•©ë¦¬ì ì¸ í¬ê¸° ë²”ìœ„ í™•ì¸
                    if 100 <= bmp_size <= 50 * 1024 * 1024 and bmp_pos + bmp_size <= len(self.data):
                        embedded_files.append({
                            'type': 'BMP Image',
                            'start': bmp_pos,
                            'size': bmp_size,
                            'end': bmp_pos + bmp_size
                        })
                except:
                    pass
            bmp_start = bmp_pos + 1
        
        # ë°œê²¬ëœ ì„ë² ë””ë“œ íŒŒì¼ë“¤ ì¶œë ¥
        if embedded_files:
            print("ë°œê²¬ëœ ì„ë² ë””ë“œ íŒŒì¼ë“¤:")
            for i, file_info in enumerate(embedded_files, 1):
                print(f"  {i}. {file_info['type']}")
                print(f"     ìœ„ì¹˜: 0x{file_info['start']:08x} - 0x{file_info['end']:08x}")
                print(f"     í¬ê¸°: {file_info['size']:,} bytes ({file_info['size']/1024:.1f} KB)")
                
                # PNGì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
                if file_info['type'] == 'PNG Image':
                    self.analyze_png_details(file_info['start'])
                # BMPì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ ì¶”ì¶œ
                elif file_info['type'] == 'BMP Image':
                    self.analyze_bmp_details(file_info['start'])
        else:
            print("ì„ë² ë””ë“œ íŒŒì¼ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def analyze_png_details(self, png_start):
        """PNG íŒŒì¼ì˜ ì„¸ë¶€ ì •ë³´ ë¶„ì„"""
        try:
            # IHDR ì²­í¬ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ
            ihdr_pos = self.data.find(b'IHDR', png_start)
            if ihdr_pos != -1:
                # IHDR ë°ì´í„°ëŠ” IHDR ë¬¸ìì—´ ë°”ë¡œ ë‹¤ìŒ 13ë°”ì´íŠ¸
                ihdr_data = self.data[ihdr_pos + 4:ihdr_pos + 17]
                if len(ihdr_data) >= 13:
                    width, height, bit_depth, color_type = struct.unpack('>IIBBB', ihdr_data[:9])
                    print(f"       PNG ì •ë³´: {width}x{height}, {bit_depth}bit, ì»¬ëŸ¬íƒ€ì…={color_type}")
            
            # í…ìŠ¤íŠ¸ ì²­í¬ ì°¾ê¸°
            text_chunks = [b'tEXt', b'iTXt', b'zTXt']
            for chunk_type in text_chunks:
                chunk_pos = self.data.find(chunk_type, png_start)
                if chunk_pos != -1:
                    # ì²­í¬ ê¸¸ì´ ì½ê¸° (ì²­í¬ íƒ€ì… 4ë°”ì´íŠ¸ ì „)
                    length_data = self.data[chunk_pos-4:chunk_pos]
                    if len(length_data) == 4:
                        chunk_length = struct.unpack('>I', length_data)[0]
                        if chunk_length < 1000:  # í•©ë¦¬ì ì¸ í¬ê¸° ì œí•œ
                            text_data = self.data[chunk_pos+4:chunk_pos+4+chunk_length]
                            # ì¸ì‡„ ê°€ëŠ¥í•œ ë¬¸ìë§Œ ì¶”ì¶œ
                            readable_text = ''.join(chr(b) if 32 <= b <= 126 else ' ' for b in text_data[:100])
                            print(f"       í…ìŠ¤íŠ¸ ì •ë³´: {readable_text.strip()}")
                            break
        except:
            pass
    
    def analyze_bmp_details(self, bmp_start):
        """BMP íŒŒì¼ì˜ ì„¸ë¶€ ì •ë³´ ë¶„ì„"""
        try:
            # BMP í—¤ë” ë¶„ì„ (ìµœì†Œ 54ë°”ì´íŠ¸ í•„ìš”)
            if bmp_start + 54 <= len(self.data):
                # BMP íŒŒì¼ í—¤ë” (14ë°”ì´íŠ¸)
                file_size = struct.unpack('<I', self.data[bmp_start + 2:bmp_start + 6])[0]
                data_offset = struct.unpack('<I', self.data[bmp_start + 10:bmp_start + 14])[0]
                
                # DIB í—¤ë” (ìµœì†Œ 40ë°”ì´íŠ¸)
                dib_header_size = struct.unpack('<I', self.data[bmp_start + 14:bmp_start + 18])[0]
                
                if dib_header_size >= 40:  # BITMAPINFOHEADER ë˜ëŠ” ë” í° í—¤ë”
                    width = struct.unpack('<i', self.data[bmp_start + 18:bmp_start + 22])[0]
                    height = struct.unpack('<i', self.data[bmp_start + 22:bmp_start + 26])[0]
                    planes = struct.unpack('<H', self.data[bmp_start + 26:bmp_start + 28])[0]
                    bit_count = struct.unpack('<H', self.data[bmp_start + 28:bmp_start + 30])[0]
                    compression = struct.unpack('<I', self.data[bmp_start + 30:bmp_start + 34])[0]
                    
                    # ì••ì¶• íƒ€ì… í•´ì„
                    compression_types = {
                        0: 'BI_RGB (ë¬´ì••ì¶•)',
                        1: 'BI_RLE8',
                        2: 'BI_RLE4',
                        3: 'BI_BITFIELDS'
                    }
                    compression_str = compression_types.get(compression, f'ì•Œ ìˆ˜ ì—†ìŒ ({compression})')
                    
                    print(f"       BMP ì •ë³´: {abs(width)}x{abs(height)}, {bit_count}bit, {compression_str}")
                    if height < 0:
                        print(f"       (ìƒí•˜ ë°˜ì „ ì´ë¯¸ì§€)")
        except:
            pass
    
    def analyze_entropy(self, block_size=1024):
        """ì—”íŠ¸ë¡œí”¼ ë¶„ì„ìœ¼ë¡œ ì••ì¶•/ì•”í˜¸í™” ì˜ì—­ ê°ì§€"""
        print(f"\n=== ì—”íŠ¸ë¡œí”¼ ë¶„ì„ (ë¸”ë¡ í¬ê¸°: {block_size}ë°”ì´íŠ¸) ===")
        
        import math
        
        high_entropy_blocks = []
        low_entropy_blocks = []
        
        for i in range(0, len(self.data), block_size):
            block = self.data[i:i+block_size]
            if len(block) < block_size // 2:  # ë„ˆë¬´ ì‘ì€ ë¸”ë¡ì€ ê±´ë„ˆë›°ê¸°
                continue
                
            # ë°”ì´íŠ¸ ë¹ˆë„ ê³„ì‚°
            byte_counts = defaultdict(int)
            for byte in block:
                byte_counts[byte] += 1
            
            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
            entropy = 0
            for count in byte_counts.values():
                p = count / len(block)
                if p > 0:
                    entropy -= p * math.log2(p)
            
            # ë†’ì€ ì—”íŠ¸ë¡œí”¼ (ì••ì¶•/ì•”í˜¸í™” ê°€ëŠ¥ì„±) ë˜ëŠ” ë‚®ì€ ì—”íŠ¸ë¡œí”¼ (ë°˜ë³µ íŒ¨í„´) ë¸”ë¡ ê¸°ë¡
            if entropy > 7.5:
                high_entropy_blocks.append((i, entropy))
            elif entropy < 2.0:
                low_entropy_blocks.append((i, entropy))
        
        if high_entropy_blocks:
            print("ë†’ì€ ì—”íŠ¸ë¡œí”¼ ì˜ì—­ (ì••ì¶•/ì•”í˜¸í™” ê°€ëŠ¥ì„±):")
            for offset, entropy in high_entropy_blocks[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                print(f"  ì˜¤í”„ì…‹ 0x{offset:08x}: ì—”íŠ¸ë¡œí”¼ {entropy:.2f}")
        
        if low_entropy_blocks:
            print("ë‚®ì€ ì—”íŠ¸ë¡œí”¼ ì˜ì—­ (ë°˜ë³µ íŒ¨í„´/ë¹ˆ ê³µê°„):")
            for offset, entropy in low_entropy_blocks[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                print(f"  ì˜¤í”„ì…‹ 0x{offset:08x}: ì—”íŠ¸ë¡œí”¼ {entropy:.2f}")
    
    def analyze_structure(self):
        """íŒŒì¼ êµ¬ì¡° ë¶„ì„"""
        print("\n=== êµ¬ì¡° ë¶„ì„ ===")
        
        # 32ë¹„íŠ¸/64ë¹„íŠ¸ ì •ë ¬ í™•ì¸
        null_sequences = []
        i = 0
        while i < len(self.data) - 4:
            if self.data[i:i+4] == b'\x00\x00\x00\x00':
                start = i
                while i < len(self.data) and self.data[i] == 0:
                    i += 1
                null_sequences.append((start, i - start))
            else:
                i += 1
        
        if null_sequences:
            print("NULL ë°”ì´íŠ¸ ì‹œí€€ìŠ¤ (íŒ¨ë”©/ì •ë ¬ ê°€ëŠ¥ì„±):")
            for start, length in null_sequences[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                print(f"  ì˜¤í”„ì…‹ 0x{start:08x}: {length}ë°”ì´íŠ¸")
        
        # 16ë°”ì´íŠ¸ ì •ë ¬ êµ¬ì¡° í™•ì¸ (UEFIì—ì„œ ì¼ë°˜ì )
        aligned_positions = []
        for i in range(0, len(self.data), 16):
            if i + 16 <= len(self.data):
                block = self.data[i:i+16]
                # íŠ¹ë³„í•œ íŒ¨í„´ì´ë‚˜ í—¤ë” ê°™ì€ êµ¬ì¡° í™•ì¸
                if not all(b == 0 for b in block) and not all(b == 0xff for b in block):
                    # ì¸ì‡„ ê°€ëŠ¥í•œ ë¬¸ìê°€ ìˆëŠ”ì§€ í™•ì¸
                    printable_count = sum(1 for b in block if 32 <= b <= 126)
                    if printable_count >= 4:  # ìµœì†Œ 4ê°œì˜ ì¸ì‡„ ê°€ëŠ¥í•œ ë¬¸ì
                        aligned_positions.append(i)
        
        if aligned_positions:
            print("16ë°”ì´íŠ¸ ì •ë ¬ëœ í…ìŠ¤íŠ¸/êµ¬ì¡° ë¸”ë¡:")
            for pos in aligned_positions[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                block = self.data[pos:pos+16]
                text = ''.join(chr(b) if 32 <= b <= 126 else '.' for b in block)
                print(f"  ì˜¤í”„ì…‹ 0x{pos:08x}: {text}")
    
    def generate_summary(self):
        """ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        print("\n" + "="*60)
        print("=== íŒŒì¼ ë¶„ì„ ìš”ì•½ ===")
        print("="*60)
        
        print(f"íŒŒì¼ëª…: {os.path.basename(self.file_path)}")
        print(f"í¬ê¸°: {self.file_size:,} bytes ({self.file_size / 1024 / 1024:.2f} MB)")
        
        # íŒŒì¼ í™•ì¥ì ê¸°ë°˜ ì¶”ì •
        if 'Section_Raw' in self.file_path and '.bin' in self.file_path:
            print("íŒŒì¼ ìœ í˜•: UEFI íŒì›¨ì–´ ì„¹ì…˜ ì¶”ì¶œ íŒŒì¼")
            print("ì˜ˆìƒ ë‚´ìš©: UEFI ëª¨ë“ˆ, ë“œë¼ì´ë²„, ë˜ëŠ” ì„¤ì • ë°ì´í„°")
        
        # ë°”ì´íŠ¸ ë¶„í¬ í†µê³„
        byte_counts = defaultdict(int)
        for byte in self.data[:min(10000, len(self.data))]:  # ì²˜ìŒ 10KBë§Œ ë¶„ì„
            byte_counts[byte] += 1
        
        most_common = sorted(byte_counts.items(), key=lambda x: x[1], reverse=True)
        print(f"\nê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” ë°”ì´íŠ¸ê°’ (ì²˜ìŒ 10KB ê¸°ì¤€):")
        for byte_val, count in most_common[:5]:
            percentage = (count / min(10000, len(self.data))) * 100
            print(f"  0x{byte_val:02x} ({byte_val}): {count}íšŒ ({percentage:.1f}%)")
    
    def collect_analysis_data(self):
        """ë¶„ì„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜"""
        from datetime import datetime
        import math
        
        analysis_data = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'file_info': {
                'filename': os.path.basename(self.file_path),
                'filepath': self.file_path,
                'size_bytes': self.file_size,
                'size_mb': round(self.file_size / 1024 / 1024, 2)
            },
            'magic_bytes': [],
            'magic_pattern_frequency': {},
            'patterns': {},
            'pattern_frequency': {},
            'embedded_files': [],
            'entropy_analysis': {
                'high_entropy': [],
                'low_entropy': []
            },
            'structure_analysis': {
                'null_sequences': [],
                'aligned_blocks': []
            },
            'byte_statistics': {}
        }
        
        # ë§¤ì§ ë°”ì´íŠ¸ ë¶„ì„
        magic_patterns = {
            b'MZ': 'PE/DOS Executable',
            b'PE\x00\x00': 'PE Header',
            b'\x7fELF': 'ELF Binary',
            b'PK\x03\x04': 'ZIP Archive',
            b'\x1f\x8b': 'GZIP',
            b'BM': 'Bitmap Image',
            b'\xff\xd8\xff': 'JPEG Image',
            b'\x89PNG': 'PNG Image',
            b'GIF8': 'GIF Image',
            b'RIFF': 'RIFF Container',
            b'_FVH': 'UEFI Firmware Volume',
            b'$FV$': 'UEFI Firmware Volume Signature'
        }
        
        # ë§¤ì§ ë°”ì´íŠ¸ íŒ¨í„´ ë¹ˆë„ ìˆ˜ì§‘
        for magic_bytes, description in magic_patterns.items():
            count = self.data.count(magic_bytes)
            if count > 0:
                analysis_data['magic_pattern_frequency'][binascii.hexlify(magic_bytes).decode()] = {
                    'description': description,
                    'count': count,
                    'frequency_per_mb': round(count / (self.file_size / 1024 / 1024), 2) if self.file_size > 0 else 0
                }
        
        for length in [2, 3, 4, 8, 16]:
            if len(self.data) >= length:
                header = self.data[:length]
                for magic, description in magic_patterns.items():
                    if header.startswith(magic):
                        analysis_data['magic_bytes'].append({
                            'bytes': binascii.hexlify(magic).decode(),
                            'description': description
                        })
        
        # íŒ¨í„´ ë¶„ì„
        patterns = {
            b'UEFI': 'UEFI ë¬¸ìì—´',
            b'BIOS': 'BIOS ë¬¸ìì—´',
            b'Award': 'Award BIOS',
            b'AMI': 'AMI BIOS',
            b'Phoenix': 'Phoenix BIOS',
            b'ASUS': 'ASUS ê´€ë ¨',
            b'Intel': 'Intel ê´€ë ¨',
            b'AMD': 'AMD ê´€ë ¨',
            b'\x89PNG': 'PNG ì´ë¯¸ì§€',
            b'\xff\xd8\xff': 'JPEG ì´ë¯¸ì§€',
            b'BM': 'BMP ì´ë¯¸ì§€',
            b'\x00' * 16: '16ë°”ì´íŠ¸ NULL íŒ¨í„´',
            b'\xff' * 16: '16ë°”ì´íŠ¸ 0xFF íŒ¨í„´',
            b'GIF8': 'GIF ì´ë¯¸ì§€',
            b'RIFF': 'RIFF íŒŒì¼',
            b'IEND': 'PNG ì¢…ë£Œ ë§ˆì»¤'
        }
        
        # íŒ¨í„´ ë¹ˆë„ í†µê³„ ìˆ˜ì§‘
        for pattern, description in patterns.items():
            count = self.data.count(pattern)
            analysis_data['pattern_frequency'][description] = {
                'pattern_hex': binascii.hexlify(pattern).decode() if len(pattern) <= 16 else binascii.hexlify(pattern[:16]).decode() + '...',
                'count': count,
                'density_per_kb': round(count / (self.file_size / 1024), 3) if self.file_size > 0 else 0,
                'percentage_of_file': round((count * len(pattern) / self.file_size) * 100, 4) if self.file_size > 0 else 0
            }
        
        for pattern, description in patterns.items():
            count = self.data.count(pattern)
            if count > 0:
                positions = []
                start = 0
                for _ in range(min(count, 5)):
                    pos = self.data.find(pattern, start)
                    if pos != -1:
                        positions.append(f"0x{pos:08x}")
                        start = pos + 1
                    else:
                        break
                analysis_data['patterns'][description] = {
                    'count': count,
                    'positions': positions
                }
        
        # ì„ë² ë””ë“œ íŒŒì¼ ë¶„ì„ (ëª¨ë“  íŒŒì¼ íƒ€ì…ì„ í†µí•©í•˜ì—¬ ìœ„ì¹˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬)
        embedded_files = []
        
        # PNG íŒŒì¼ ì°¾ê¸°
        png_start = 0
        while True:
            png_pos = self.data.find(b'\x89PNG\r\n\x1a\n', png_start)
            if png_pos == -1:
                break
            
            iend_pos = self.data.find(b'IEND\xaeB`\x82', png_pos)
            if iend_pos != -1:
                png_size = iend_pos + 8 - png_pos
                
                # PNG ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ
                png_info = {
                    'type': 'PNG Image',
                    'start_pos': png_pos,  # ì •ë ¬ìš© ìˆ«ì ìœ„ì¹˜
                    'start': f"0x{png_pos:08x}",
                    'end': f"0x{png_pos + png_size:08x}",
                    'size_bytes': png_size,
                    'size_kb': round(png_size / 1024, 1)
                }
                
                # PNG í—¤ë” ì •ë³´ ì¶”ì¶œ
                try:
                    ihdr_pos = self.data.find(b'IHDR', png_pos)
                    if ihdr_pos != -1:
                        ihdr_data = self.data[ihdr_pos + 4:ihdr_pos + 17]
                        if len(ihdr_data) >= 13:
                            width, height, bit_depth, color_type = struct.unpack('>IIBBB', ihdr_data[:9])
                            png_info['width'] = width
                            png_info['height'] = height
                            png_info['bit_depth'] = bit_depth
                            png_info['color_type'] = color_type
                except:
                    pass
                
                embedded_files.append(png_info)
            png_start = png_pos + 1
        
        # BMP íŒŒì¼ ë¶„ì„
        bmp_start = 0
        while True:
            bmp_pos = self.data.find(b'BM', bmp_start)
            if bmp_pos == -1:
                break
            
            if bmp_pos + 6 <= len(self.data):
                try:
                    bmp_size_bytes = self.data[bmp_pos + 2:bmp_pos + 6]
                    bmp_size = struct.unpack('<I', bmp_size_bytes)[0]
                    
                    if 100 <= bmp_size <= 50 * 1024 * 1024 and bmp_pos + bmp_size <= len(self.data):
                        # BMP ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ
                        bmp_info = {
                            'type': 'BMP Image',
                            'start_pos': bmp_pos,  # ì •ë ¬ìš© ìˆ«ì ìœ„ì¹˜
                            'start': f"0x{bmp_pos:08x}",
                            'end': f"0x{bmp_pos + bmp_size:08x}",
                            'size_bytes': bmp_size,
                            'size_kb': round(bmp_size / 1024, 1)
                        }
                        
                        # BMP í—¤ë” ì •ë³´ ì¶”ì¶œ
                        try:
                            if bmp_pos + 54 <= len(self.data):
                                dib_header_size = struct.unpack('<I', self.data[bmp_pos + 14:bmp_pos + 18])[0]
                                if dib_header_size >= 40:
                                    width = struct.unpack('<i', self.data[bmp_pos + 18:bmp_pos + 22])[0]
                                    height = struct.unpack('<i', self.data[bmp_pos + 22:bmp_pos + 26])[0]
                                    bit_count = struct.unpack('<H', self.data[bmp_pos + 28:bmp_pos + 30])[0]
                                    bmp_info['width'] = abs(width)
                                    bmp_info['height'] = abs(height)
                                    bmp_info['bit_depth'] = bit_count
                        except:
                            pass
                        
                        embedded_files.append(bmp_info)
                except:
                    pass
            bmp_start = bmp_pos + 1
        
        # JPEG íŒŒì¼ ë¶„ì„
        jpeg_start = 0
        while True:
            jpeg_pos = self.data.find(b'\xff\xd8\xff', jpeg_start)
            if jpeg_pos == -1:
                break
            
            # JPEG ë ì°¾ê¸° (FFD9)
            search_pos = jpeg_pos + 3
            jpeg_end = -1
            while search_pos < len(self.data) - 1:
                if self.data[search_pos:search_pos+2] == b'\xff\xd9':
                    jpeg_end = search_pos + 2
                    break
                search_pos += 1
            
            if jpeg_end != -1:
                jpeg_size = jpeg_end - jpeg_pos
                
                # JPEG ì„¸ë¶€ ì •ë³´ ì¶”ì¶œ
                jpeg_info = {
                    'type': 'JPEG Image',
                    'start_pos': jpeg_pos,  # ì •ë ¬ìš© ìˆ«ì ìœ„ì¹˜
                    'start': f"0x{jpeg_pos:08x}",
                    'end': f"0x{jpeg_end:08x}",
                    'size_bytes': jpeg_size,
                    'size_kb': round(jpeg_size / 1024, 1)
                }
                
                # JPEG í—¤ë” ì •ë³´ ì¶”ì¶œ
                try:
                    # JFIF í—¤ë” í™•ì¸
                    if jpeg_pos + 20 <= len(self.data):
                        if b'JFIF' in self.data[jpeg_pos:jpeg_pos+20]:
                            jfif_pos = self.data.find(b'JFIF', jpeg_pos)
                            if jfif_pos != -1 and jfif_pos + 14 <= len(self.data):
                                version_major = self.data[jfif_pos + 5]
                                version_minor = self.data[jfif_pos + 6]
                                units = self.data[jfif_pos + 7]
                                x_density = struct.unpack('>H', self.data[jfif_pos + 8:jfif_pos + 10])[0]
                                y_density = struct.unpack('>H', self.data[jfif_pos + 10:jfif_pos + 12])[0]
                                jpeg_info['jfif_version'] = f"{version_major}.{version_minor}"
                                jpeg_info['density'] = f"{x_density}x{y_density}"
                    
                    # SOF ë§ˆì»¤ì—ì„œ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ ì¶”ì¶œ
                    sof_markers = [b'\xff\xc0', b'\xff\xc1', b'\xff\xc2']  # SOF0, SOF1, SOF2
                    for sof_marker in sof_markers:
                        sof_pos = self.data.find(sof_marker, jpeg_pos)
                        if sof_pos != -1 and sof_pos + 9 <= len(self.data):
                            precision = self.data[sof_pos + 4]
                            height = struct.unpack('>H', self.data[sof_pos + 5:sof_pos + 7])[0]
                            width = struct.unpack('>H', self.data[sof_pos + 7:sof_pos + 9])[0]
                            components = self.data[sof_pos + 9]
                            jpeg_info['width'] = width
                            jpeg_info['height'] = height
                            jpeg_info['bit_depth'] = precision
                            jpeg_info['components'] = components
                            break
                except:
                    pass
                
                embedded_files.append(jpeg_info)
            jpeg_start = jpeg_pos + 1
        
        # ëª¨ë“  ì„ë² ë””ë“œ íŒŒì¼ì„ ìœ„ì¹˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        embedded_files.sort(key=lambda x: x['start_pos'])
        
        # start_pos í•„ë“œ ì œê±° (ì •ë ¬ì—ë§Œ ì‚¬ìš©)
        for file_info in embedded_files:
            del file_info['start_pos']
        
        analysis_data['embedded_files'] = embedded_files
        
        # ì—”íŠ¸ë¡œí”¼ ë¶„ì„
        block_size = 1024
        for i in range(0, len(self.data), block_size):
            block = self.data[i:i+block_size]
            if len(block) < block_size // 2:
                continue
                
            byte_counts = defaultdict(int)
            for byte in block:
                byte_counts[byte] += 1
            
            entropy = 0
            for count in byte_counts.values():
                p = count / len(block)
                if p > 0:
                    entropy -= p * math.log2(p)
            
            if entropy > 7.5:
                analysis_data['entropy_analysis']['high_entropy'].append({
                    'offset': f"0x{i:08x}",
                    'entropy': round(entropy, 2)
                })
            elif entropy < 2.0:
                analysis_data['entropy_analysis']['low_entropy'].append({
                    'offset': f"0x{i:08x}",
                    'entropy': round(entropy, 2)
                })
        
        # êµ¬ì¡° ë¶„ì„ - NULL ì‹œí€€ìŠ¤
        null_sequences = []
        i = 0
        while i < len(self.data) - 4:
            if self.data[i:i+4] == b'\x00\x00\x00\x00':
                start = i
                while i < len(self.data) and self.data[i] == 0:
                    i += 1
                null_sequences.append({
                    'offset': f"0x{start:08x}",
                    'length': i - start
                })
            else:
                i += 1
        analysis_data['structure_analysis']['null_sequences'] = null_sequences[:10]
        
        # ë°”ì´íŠ¸ í†µê³„
        byte_counts = defaultdict(int)
        for byte in self.data[:min(10000, len(self.data))]:
            byte_counts[byte] += 1
        
        most_common = sorted(byte_counts.items(), key=lambda x: x[1], reverse=True)
        for byte_val, count in most_common[:5]:
            percentage = (count / min(10000, len(self.data))) * 100
            analysis_data['byte_statistics'][f"0x{byte_val:02x}"] = {
                'count': count,
                'percentage': round(percentage, 1)
            }
        
        return analysis_data
    
    def save_analysis_results_txt(self, output_file=None):
        """ë¶„ì„ ê²°ê³¼ë¥¼ TXT íŒŒì¼ë¡œ ì €ì¥"""
        if output_file is None:
            base_name = os.path.splitext(self.file_path)[0]
            output_file = f"{base_name}_analysis.txt"
        
        try:
            analysis_data = self.collect_analysis_data()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("="*80 + "\n")
                f.write("ë°”ì´ë„ˆë¦¬ íŒŒì¼ ë¶„ì„ ë³´ê³ ì„œ\n")
                f.write("="*80 + "\n\n")
                
                # ê¸°ë³¸ ì •ë³´
                f.write(f"ë¶„ì„ ì¼ì‹œ: {analysis_data['timestamp']}\n")
                f.write(f"íŒŒì¼ëª…: {analysis_data['file_info']['filename']}\n")
                f.write(f"íŒŒì¼ ê²½ë¡œ: {analysis_data['file_info']['filepath']}\n")
                f.write(f"íŒŒì¼ í¬ê¸°: {analysis_data['file_info']['size_bytes']:,} bytes ({analysis_data['file_info']['size_mb']} MB)\n\n")
                
                # ë§¤ì§ ë°”ì´íŠ¸
                if analysis_data['magic_bytes']:
                    f.write("ë§¤ì§ ë°”ì´íŠ¸ ë¶„ì„\n")
                    f.write("-" * 40 + "\n")
                    for magic in analysis_data['magic_bytes']:
                        f.write(f"  {magic['bytes']}: {magic['description']}\n")
                    f.write("\n")
                
                # ë§¤ì§ íŒ¨í„´ ë¹ˆë„
                if analysis_data['magic_pattern_frequency']:
                    f.write("ë§¤ì§ íŒ¨í„´ ë¹ˆë„ ë¶„ì„\n")
                    f.write("-" * 40 + "\n")
                    for pattern_hex, info in analysis_data['magic_pattern_frequency'].items():
                        f.write(f"  {pattern_hex} ({info['description']}): {info['count']}ê°œ ({info['frequency_per_mb']}/MB)\n")
                    f.write("\n")
                
                # íŒ¨í„´ ë¶„ì„
                if analysis_data['patterns']:
                    f.write("íŒ¨í„´ ë¶„ì„\n")
                    f.write("-" * 40 + "\n")
                    for pattern, info in analysis_data['patterns'].items():
                        f.write(f"  {pattern}: {info['count']}ê°œ ë°œê²¬\n")
                        f.write(f"    ìœ„ì¹˜: {', '.join(info['positions'])}\n")
                        if info['count'] > 5:
                            f.write(f"    (ì´ {info['count']}ê°œ, ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ)\n")
                    f.write("\n")
                
                # íŒ¨í„´ ë¹ˆë„ í†µê³„
                if analysis_data['pattern_frequency']:
                    f.write("íŒ¨í„´ ë¹ˆë„ í†µê³„\n")
                    f.write("-" * 40 + "\n")
                    f.write("íŒ¨í„´                  | ê°œìˆ˜      | ë°€ë„(/KB) | ë¹„ìœ¨(%)\n")
                    f.write("-" * 60 + "\n")
                    for description, info in analysis_data['pattern_frequency'].items():
                        if info['count'] > 0:  # ë°œê²¬ëœ íŒ¨í„´ë§Œ í‘œì‹œ
                            f.write(f"{description:<20} | {info['count']:>8} | {info['density_per_kb']:>8} | {info['percentage_of_file']:>6}\n")
                    f.write("\n")
                
                # ì„ë² ë””ë“œ íŒŒì¼
                if analysis_data['embedded_files']:
                    f.write("ì„ë² ë””ë“œ íŒŒì¼ ë¶„ì„\n")
                    f.write("-" * 40 + "\n")
                    for i, file_info in enumerate(analysis_data['embedded_files'], 1):
                        f.write(f"  {i}. {file_info['type']}\n")
                        f.write(f"     ìœ„ì¹˜: {file_info['start']} - {file_info['end']}\n")
                        f.write(f"     í¬ê¸°: {file_info['size_bytes']:,} bytes ({file_info['size_kb']} KB)\n")
                        if 'width' in file_info:
                            if file_info['type'] == 'JPEG Image':
                                f.write(f"     ì´ë¯¸ì§€ ì •ë³´: {file_info['width']}x{file_info['height']}, {file_info['bit_depth']}bit, {file_info.get('components', 'N/A')}ì»´í¬ë„ŒíŠ¸\n")
                                if 'jfif_version' in file_info:
                                    f.write(f"     JFIF v{file_info['jfif_version']}, ë°€ë„: {file_info.get('density', 'N/A')} DPI\n")
                            else:
                                f.write(f"     ì´ë¯¸ì§€ ì •ë³´: {file_info['width']}x{file_info['height']}, {file_info['bit_depth']}bit\n")
                    f.write("\n")
                
                # ì—”íŠ¸ë¡œí”¼ ë¶„ì„
                f.write("ì—”íŠ¸ë¡œí”¼ ë¶„ì„\n")
                f.write("-" * 40 + "\n")
                if analysis_data['entropy_analysis']['high_entropy']:
                    f.write("ë†’ì€ ì—”íŠ¸ë¡œí”¼ ì˜ì—­ (ì••ì¶•/ì•”í˜¸í™” ê°€ëŠ¥ì„±):\n")
                    for entry in analysis_data['entropy_analysis']['high_entropy'][:10]:
                        f.write(f"  ì˜¤í”„ì…‹ {entry['offset']}: ì—”íŠ¸ë¡œí”¼ {entry['entropy']}\n")
                
                if analysis_data['entropy_analysis']['low_entropy']:
                    f.write("ë‚®ì€ ì—”íŠ¸ë¡œí”¼ ì˜ì—­ (ë°˜ë³µ íŒ¨í„´/ë¹ˆ ê³µê°„):\n")
                    for entry in analysis_data['entropy_analysis']['low_entropy'][:10]:
                        f.write(f"  ì˜¤í”„ì…‹ {entry['offset']}: ì—”íŠ¸ë¡œí”¼ {entry['entropy']}\n")
                f.write("\n")
                
                # êµ¬ì¡° ë¶„ì„
                if analysis_data['structure_analysis']['null_sequences']:
                    f.write("êµ¬ì¡° ë¶„ì„\n")
                    f.write("-" * 40 + "\n")
                    f.write("NULL ë°”ì´íŠ¸ ì‹œí€€ìŠ¤ (íŒ¨ë”©/ì •ë ¬ ê°€ëŠ¥ì„±):\n")
                    for seq in analysis_data['structure_analysis']['null_sequences']:
                        f.write(f"  ì˜¤í”„ì…‹ {seq['offset']}: {seq['length']}ë°”ì´íŠ¸\n")
                    f.write("\n")
                
                # ë°”ì´íŠ¸ í†µê³„
                if analysis_data['byte_statistics']:
                    f.write("ë°”ì´íŠ¸ í†µê³„ (ì²˜ìŒ 10KB ê¸°ì¤€)\n")
                    f.write("-" * 40 + "\n")
                    for byte_val, stats in analysis_data['byte_statistics'].items():
                        f.write(f"  {byte_val}: {stats['count']}íšŒ ({stats['percentage']}%)\n")
                
                f.write("\n" + "="*80 + "\n")
                f.write("ë¶„ì„ ì™„ë£Œ\n")
                f.write("="*80 + "\n")
            
            print(f"âœ“ TXT ë¶„ì„ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {output_file}")
            return True
            
        except Exception as e:
            print(f"âœ— TXT ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def save_analysis_results_md(self, output_file=None):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥ (ì›ë³¸ íŒŒì¼ê³¼ ê°™ì€ ë””ë ‰í„°ë¦¬ì— ìƒì„±)"""
        if output_file is None:
            # ì›ë³¸ íŒŒì¼ì˜ ë””ë ‰í„°ë¦¬ì™€ íŒŒì¼ëª… ë¶„ë¦¬
            original_dir = os.path.dirname(self.file_path)
            original_name = os.path.splitext(os.path.basename(self.file_path))[0]
            
            # ì›ë³¸ íŒŒì¼ ë””ë ‰í„°ë¦¬ì— MD íŒŒì¼ ìƒì„±
            output_file = os.path.join(original_dir, f"{original_name}_analysis.md")
        
        try:
            analysis_data = self.collect_analysis_data()
            
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("# ë°”ì´ë„ˆë¦¬ íŒŒì¼ ë¶„ì„ ë³´ê³ ì„œ\n\n")
                
                # ê¸°ë³¸ ì •ë³´
                f.write("## ğŸ“‹ ê¸°ë³¸ ì •ë³´\n\n")
                f.write(f"- **ë¶„ì„ ì¼ì‹œ**: {analysis_data['timestamp']}\n")
                f.write(f"- **íŒŒì¼ëª…**: `{analysis_data['file_info']['filename']}`\n")
                f.write(f"- **íŒŒì¼ ê²½ë¡œ**: `{analysis_data['file_info']['filepath']}`\n")
                f.write(f"- **íŒŒì¼ í¬ê¸°**: {analysis_data['file_info']['size_bytes']:,} bytes ({analysis_data['file_info']['size_mb']} MB)\n\n")
                
                # ë§¤ì§ ë°”ì´íŠ¸
                if analysis_data['magic_bytes']:
                    f.write("## ğŸ” ë§¤ì§ ë°”ì´íŠ¸ ë¶„ì„\n\n")
                    f.write("| ë°”ì´íŠ¸ | ì„¤ëª… |\n")
                    f.write("|--------|------|\n")
                    for magic in analysis_data['magic_bytes']:
                        f.write(f"| `{magic['bytes']}` | {magic['description']} |\n")
                    f.write("\n")
                
                # ë§¤ì§ íŒ¨í„´ ë¹ˆë„
                if analysis_data['magic_pattern_frequency']:
                    f.write("## ğŸ“Š ë§¤ì§ íŒ¨í„´ ë¹ˆë„ ë¶„ì„\n\n")
                    f.write("> ğŸ“ **Note**: ì„ë² ë””ë“œ íŒŒì¼ì„ êµ¬ì„±í•˜ëŠ” ë°”ì´ë„ˆë¦¬ ë‚´ì—ë„ ë§¤ì§ íŒ¨í„´ ë˜ëŠ” íŒ¨í„´ë“¤ì´ í¬í•¨ë  ìˆ˜ ìˆì–´, ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n")
                    f.write("| íŒ¨í„´ | ì„¤ëª… | ê°œìˆ˜ | ë¹ˆë„(/MB) |\n")
                    f.write("|------|------|------|----------|\n")
                    for pattern_hex, info in analysis_data['magic_pattern_frequency'].items():
                        f.write(f"| `{pattern_hex}` | {info['description']} | {info['count']} | {info['frequency_per_mb']} |\n")
                    f.write("\n")
                
                # íŒ¨í„´ ë¶„ì„
                if analysis_data['patterns']:
                    f.write("## ğŸ” íŒ¨í„´ ë¶„ì„\n\n")
                    f.write("> ğŸ“ **Note**: ì„ë² ë””ë“œ íŒŒì¼ì„ êµ¬ì„±í•˜ëŠ” ë°”ì´ë„ˆë¦¬ ë‚´ì—ë„ ë§¤ì§ íŒ¨í„´ ë˜ëŠ” íŒ¨í„´ë“¤ì´ í¬í•¨ë  ìˆ˜ ìˆì–´, ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n")
                    f.write("| íŒ¨í„´ | ê°œìˆ˜ | ìœ„ì¹˜ |\n")
                    f.write("|------|------|------|\n")
                    for pattern, info in analysis_data['patterns'].items():
                        positions = ', '.join(info['positions'])
                        if info['count'] > 5:
                            positions += f" (ì´ {info['count']}ê°œ)"
                        f.write(f"| {pattern} | {info['count']} | `{positions}` |\n")
                    f.write("\n")
                
                # íŒ¨í„´ ë¹ˆë„ í†µê³„
                if analysis_data['pattern_frequency']:
                    f.write("## ğŸ“ˆ íŒ¨í„´ ë¹ˆë„ í†µê³„\n\n")
                    f.write("> ğŸ“ **Note**: ì„ë² ë””ë“œ íŒŒì¼ì„ êµ¬ì„±í•˜ëŠ” ë°”ì´ë„ˆë¦¬ ë‚´ì—ë„ ë§¤ì§ íŒ¨í„´ ë˜ëŠ” íŒ¨í„´ë“¤ì´ í¬í•¨ë  ìˆ˜ ìˆì–´, ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n")
                    f.write("| íŒ¨í„´ | ê°œìˆ˜ | ë°€ë„(/KB) | íŒŒì¼ ë¹„ìœ¨(%) |\n")
                    f.write("|------|------|-----------|-------------|\n")
                    for description, info in analysis_data['pattern_frequency'].items():
                        if info['count'] > 0:  # ë°œê²¬ëœ íŒ¨í„´ë§Œ í‘œì‹œ
                            f.write(f"| {description} | {info['count']} | {info['density_per_kb']} | {info['percentage_of_file']} |\n")
                    f.write("\n")
                
                # ì„ë² ë””ë“œ íŒŒì¼
                if analysis_data['embedded_files']:
                    f.write("## ğŸ–¼ï¸ ì„ë² ë””ë“œ íŒŒì¼ ë¶„ì„\n\n")
                    f.write(f"ì´ **{len(analysis_data['embedded_files'])}ê°œ**ì˜ ì„ë² ë””ë“œ íŒŒì¼ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n")
                    
                    f.write("| # | íƒ€ì… | ìœ„ì¹˜ | í¬ê¸° | ì„¸ë¶€ì •ë³´ |\n")
                    f.write("|---|------|------|------|----------|\n")
                    for i, file_info in enumerate(analysis_data['embedded_files'], 1):
                        details = ""
                        if 'width' in file_info:
                            if file_info['type'] == 'JPEG Image':
                                if 'jfif_version' in file_info and 'density' in file_info:
                                    details = f"{file_info['width']}Ã—{file_info['height']}, {file_info['bit_depth']}bit, {file_info['components']}ì»´í¬ë„ŒíŠ¸, JFIF v{file_info['jfif_version']}"
                                else:
                                    details = f"{file_info['width']}Ã—{file_info['height']}, {file_info['bit_depth']}bit, {file_info.get('components', 'N/A')}ì»´í¬ë„ŒíŠ¸"
                            else:
                                details = f"{file_info['width']}Ã—{file_info['height']}, {file_info['bit_depth']}bit"
                        f.write(f"| {i} | {file_info['type']} | `{file_info['start']} - {file_info['end']}` | {file_info['size_bytes']:,} bytes ({file_info['size_kb']} KB) | {details} |\n")
                    f.write("\n")
                
                # ì—”íŠ¸ë¡œí”¼ ë¶„ì„
                f.write("## ğŸ“Š ì—”íŠ¸ë¡œí”¼ ë¶„ì„\n\n")
                
                if analysis_data['entropy_analysis']['high_entropy']:
                    f.write("### ğŸ”´ ë†’ì€ ì—”íŠ¸ë¡œí”¼ ì˜ì—­ (ì••ì¶•/ì•”í˜¸í™” ê°€ëŠ¥ì„±)\n\n")
                    f.write("| ì˜¤í”„ì…‹ | ì—”íŠ¸ë¡œí”¼ |\n")
                    f.write("|--------|----------|\n")
                    for entry in analysis_data['entropy_analysis']['high_entropy'][:10]:
                        f.write(f"| `{entry['offset']}` | {entry['entropy']} |\n")
                    f.write("\n")
                
                if analysis_data['entropy_analysis']['low_entropy']:
                    f.write("### ğŸŸ¢ ë‚®ì€ ì—”íŠ¸ë¡œí”¼ ì˜ì—­ (ë°˜ë³µ íŒ¨í„´/ë¹ˆ ê³µê°„)\n\n")
                    f.write("| ì˜¤í”„ì…‹ | ì—”íŠ¸ë¡œí”¼ |\n")
                    f.write("|--------|----------|\n")
                    for entry in analysis_data['entropy_analysis']['low_entropy'][:10]:
                        f.write(f"| `{entry['offset']}` | {entry['entropy']} |\n")
                    f.write("\n")
                
                # êµ¬ì¡° ë¶„ì„
                if analysis_data['structure_analysis']['null_sequences']:
                    f.write("## ğŸ—ï¸ êµ¬ì¡° ë¶„ì„\n\n")
                    f.write("### NULL ë°”ì´íŠ¸ ì‹œí€€ìŠ¤ (íŒ¨ë”©/ì •ë ¬ ê°€ëŠ¥ì„±)\n\n")
                    f.write("| ì˜¤í”„ì…‹ | ê¸¸ì´ |\n")
                    f.write("|--------|------|\n")
                    for seq in analysis_data['structure_analysis']['null_sequences']:
                        f.write(f"| `{seq['offset']}` | {seq['length']} bytes |\n")
                    f.write("\n")
                
                # ë°”ì´íŠ¸ í†µê³„
                if analysis_data['byte_statistics']:
                    f.write("## ğŸ“ˆ ë°”ì´íŠ¸ í†µê³„ (ì²˜ìŒ 10KB ê¸°ì¤€)\n\n")
                    f.write("| ë°”ì´íŠ¸ ê°’ | ê°œìˆ˜ | ë¹„ìœ¨ |\n")
                    f.write("|-----------|------|------|\n")
                    for byte_val, stats in analysis_data['byte_statistics'].items():
                        f.write(f"| `{byte_val}` | {stats['count']} | {stats['percentage']}% |\n")
                    f.write("\n")
                
                # ìš”ì•½
                f.write("## ğŸ“ ë¶„ì„ ìš”ì•½\n\n")
                
                if 'Section_Raw' in analysis_data['file_info']['filepath'] and '.bin' in analysis_data['file_info']['filepath']:
                    f.write("- **íŒŒì¼ ìœ í˜•**: UEFI íŒì›¨ì–´ ì„¹ì…˜ ì¶”ì¶œ íŒŒì¼\n")
                    f.write("- **ì˜ˆìƒ ë‚´ìš©**: UEFI ëª¨ë“ˆ, ë“œë¼ì´ë²„, ë˜ëŠ” ì„¤ì • ë°ì´í„°\n")
                
                if analysis_data['embedded_files']:
                    total_images = len(analysis_data['embedded_files'])
                    f.write(f"- **ì„ë² ë””ë“œ ì´ë¯¸ì§€**: {total_images}ê°œ ë°œê²¬\n")
                
                if analysis_data['patterns']:
                    f.write(f"- **ë°œê²¬ëœ íŒ¨í„´**: {len(analysis_data['patterns'])}ê°€ì§€\n")
                
                f.write(f"- **ë¶„ì„ ì™„ë£Œ ì‹œì **: {analysis_data['timestamp']}\n\n")
                
                f.write("---\n\n")
                f.write("*ì´ ë³´ê³ ì„œëŠ” ë°”ì´ë„ˆë¦¬ íŒŒì¼ ë¶„ì„ ë„êµ¬ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*\n")
            
            print(f"âœ“ ë§ˆí¬ë‹¤ìš´ ë¶„ì„ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {output_file}")
            return True
            
        except Exception as e:
            print(f"âœ— ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def run_full_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("ë°”ì´ë„ˆë¦¬ íŒŒì¼ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("="*60)
        
        self.load_file()
        self.analyze_magic_bytes()
        self.find_patterns()
        self.analyze_embedded_files()
        self.analyze_entropy()
        self.analyze_structure()
        self.generate_summary()
        
        # ë¶„ì„ ì™„ë£Œ í›„ ë³´ê³ ì„œ ì €ì¥
        print("\n" + "="*60)
        print("=== ë¶„ì„ ë³´ê³ ì„œ ì €ì¥ ===")
        print("="*60)
        
        # TXT ë³´ê³ ì„œ ì €ì¥
        txt_success = self.save_analysis_results_txt()
        
        # ë§ˆí¬ë‹¤ìš´ ë³´ê³ ì„œ ì €ì¥
        md_success = self.save_analysis_results_md()
        
        if txt_success and md_success:
            print("ğŸ“„ ëª¨ë“  ë¶„ì„ ë³´ê³ ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        elif txt_success or md_success:
            print("âš ï¸ ì¼ë¶€ ë¶„ì„ ë³´ê³ ì„œë§Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            print("âŒ ë¶„ì„ ë³´ê³ ì„œ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ì €ì¥ëœ íŒŒì¼ ìœ„ì¹˜ ì•ˆë‚´
        base_name = os.path.splitext(self.file_path)[0]
        print(f"\nğŸ“ ë³´ê³ ì„œ ì €ì¥ ìœ„ì¹˜:")
        print(f"   TXT: {base_name}_analysis.txt")
        print(f"   MD:  {base_name}_analysis.md")